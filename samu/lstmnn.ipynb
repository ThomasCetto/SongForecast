{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#from tqdm.notebook import tqdm, trange\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from copy import deepcopy\n",
    "import matplotlib as plt\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from music21 import *\n",
    "from np_utils import np_utils\n",
    "from os import listdir\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sequence_length = 32\n",
    "\n",
    "def to_sliding_windows(file_notes):\n",
    "    pass\n",
    "    # fare in modo che le seuenze siano solo tra i file\n",
    "\n",
    "DIR = '../midiFiles'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_notes(file_limit):\n",
    "    notes = pd.Series(dtype= 'int32')\n",
    "\n",
    "    i=0\n",
    "\n",
    "    dicto = {}\n",
    "    n_vocab = 0\n",
    "\n",
    "    for file in tqdm(listdir(DIR)):\n",
    "        if not \"mid\" in file:\n",
    "            continue\n",
    "\n",
    "        if i > file_limit:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "        midifile = converter.parse(DIR + '/' + file)\n",
    "\n",
    "        \"\"\"\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midifile)\n",
    "            notes_to_parse = s2.parts[0].recurse()\n",
    "            s2.show('text')\n",
    "        except: # file has notes in a flat structure\n",
    "            print(\"flar\")\n",
    "            notes_to_parse = midifile.flat.notes\n",
    "        \"\"\"\n",
    "        #ho solo il piano\n",
    "        notes_to_parse = midifile.flat.notes\n",
    "        notes_file = []\n",
    "\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "\n",
    "            niu = ''\n",
    "\n",
    "            if isinstance(element, note.Note):\n",
    "                niu = str(element.pitch)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                niu= '.'.join(str(n) for n in element.normalOrder)\n",
    "\n",
    "            if not niu in dicto:\n",
    "                dicto[niu] = n_vocab\n",
    "                #brutto ma piu' efficiente\n",
    "                notes_file.append(n_vocab)\n",
    "                n_vocab += 1\n",
    "            else:\n",
    "                notes_file.append(dicto[niu])\n",
    "\n",
    "        notes = pd.concat([notes, pd.Series(notes_file)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes, dicto, n_vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "notepd, note_to_int, n_vocab = get_notes(100)\n",
    "\n",
    "#network_input, network_output = prepare_sequences(notes, n_vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "np_array = notepd.to_numpy().reshape(-1,1)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(np_array)\n",
    "input_nn = scaler.transform(np_array)\n",
    "input_nn = input_nn[ :, 0]\n",
    "print(input_nn.shape)\n",
    "\n",
    "input_nn = pd.Series(input_nn)\n",
    "\n",
    "\n",
    "#sliding window division, return rolling object\n",
    "niu_input_nn = pd.Series(dtype= 'int32')\n",
    "for window in tqdm(input_nn.rolling(window= sequence_length.bit_length()), total=len(input_nn)):\n",
    "    niu_input_nn = pd.concat([niu_input_nn, window], ignore_index=True)\n",
    "\n",
    "input_nn = niu_input_nn\n",
    "\n",
    "input_nn = input_nn.apply(lambda x: x)\n",
    "input_nn = input_nn.iloc[0:-1]\n",
    "# tolgo l'ultimo perche' non ho un valore output\n",
    "output_nn = notepd.iloc[sequence_length:]#tutti gli elementio a partire dal primo output\n",
    "\n",
    "n_patterns = len(input_nn)\n",
    "\n",
    "# reshape the input into a format compatible with LSTM layers\n",
    "input_nn = pd.reshape(input_nn, (n_patterns, sequence_length, 1))\n",
    "\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "output_nn = output_nn.astype(\"category\")\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "output_nn = lb.fit_transform(output_nn)\n",
    "\n",
    "int_to_note = dict((v, k) for k, v in note_to_int.items())\n",
    "\n",
    "#revers from hotone to abc\n",
    "#output_nn = lb.inverse_transform(output_nn, threshold=0)\n",
    "#output_nn = output_nn.map(int_to_note)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(input_nn, output_nn, test_size=0.15, shuffle=False)\n",
    "# la nn che faccio e' statafull, non stateless\n",
    "# comunque faccio solo il train e non solo il test\n",
    "\n",
    "batch_size = 50\n",
    "train = TensorDataset(input_nn, output_nn)\n",
    "# Create data loaders.\n",
    "#test = DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "train = DataLoader(train, batch_size=batch_size, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
    "\n",
    "\n",
    "model = LSTMNetwork(n_vocab).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# utilizzo con one hot encoding\n",
    "#_, targets = y1.max(dim=0)\n",
    "#nn.CrossEntropyLoss()(out, Variable(targets))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trainf(dataloader, model, loss_fn, optimizer):\n",
    "    global best_model\n",
    "    train_losses = []\n",
    "    best_loss = float(\"inf\")\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch , (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        loss = float(\"inf\")\n",
    "        optimizer.zero_grad()\n",
    "        # Compute prediction error\n",
    "        for x_line, y_line in zip(X, Y):\n",
    "            pred = model(x_line)\n",
    "            #hot one encoding\n",
    "            _, targets = pred.max(dim=0)\n",
    "            loss = loss_fn(y_line, targets)\n",
    "            loss.backward()\n",
    "        # Backpropagation\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            train_losses.append(loss)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "train_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_losses = trainf(train, model, loss_fn, optimizer)\n",
    "    train_losses.append(epoch_losses)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluateMultinomial(net, prime_seq, predict_len, temperature=0.8):\n",
    "    '''\n",
    "    Arguments:\n",
    "    prime_seq - priming sequence (converted t)\n",
    "    predict_len - number of notes to predict for after prime sequence\n",
    "    '''\n",
    "    hidden = net.init_hidden()\n",
    "\n",
    "    predicted = prime_seq.copy()\n",
    "    prime_seq = torch.tensor(prime_seq, dtype = torch.long).to(device)\n",
    "\n",
    "\n",
    "    # \"Building up\" the hidden state using the prime sequence\n",
    "    for p in range(len(prime_seq) - 1):\n",
    "        input = prime_seq[p]\n",
    "        _, hidden = net(input, hidden)\n",
    "\n",
    "    # Last character of prime sequence\n",
    "    input = prime_seq[-1]\n",
    "\n",
    "    # For every index to predict\n",
    "    for p in range(predict_len):\n",
    "\n",
    "        # Pass the inputs to the model - output has dimension n_pitches - scores for each of the possible characters\n",
    "        output, hidden = net(input, hidden)\n",
    "        # Sample from the network output as a multinomial distribution\n",
    "        output = output.data.view(-1).div(temperature).exp()\n",
    "        predicted_id = torch.multinomial(output, 1)\n",
    "\n",
    "        # Add predicted index to the list and use as next input\n",
    "        predicted.append(predicted_id.item())\n",
    "        input = predicted_id\n",
    "\n",
    "    return predicted\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#generated_seq = evaluate(model, [100, 101, 102, 101, 100], predict_len = 100)\n",
    "generated_seq_multinomial = evaluateMultinomial(model, [100, 101, 102, 101, 100], predict_len = 500, temperature = 1.2)\n",
    "#print(generated_seq)\n",
    "print(generated_seq_multinomial)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#generated_seq = [int_to_note[e] for e in generated_seq]\n",
    "generated_seq_multinomial = [int_to_note[e] for e in generated_seq_multinomial]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    return midi_stream"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generated_stream = create_midi(generated_seq_multinomial)\n",
    "generated_stream.write('midi', fp='output/uno.midi')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
